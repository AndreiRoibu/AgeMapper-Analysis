{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import sys\n",
    "import argparse\n",
    "import h5py\n",
    "from scipy.stats import t as student_t\n",
    "from statsmodels.stats import multitest as mt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, permutation_test\n",
    "import sys\n",
    "import argparse\n",
    "import h5py\n",
    "from scipy.stats import t as student_t\n",
    "from statsmodels.stats import multitest as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDP_df = pd.read_pickle('male_IDP.pkl')\n",
    "vars_df = pd.read_pickle('female_vars.pkl')\n",
    "# IDP_names = np.loadtxt(\"IDP_names.txt\", dtype=str, delimiter='\\n')\n",
    "# IDP_categories = np.loadtxt(\"IDP_categories.txt\", dtype=str, delimiter='\\n')\n",
    "with open('../Analsysis Female New/varsHeader.txt') as f:\n",
    "    varsHeader = f.readlines()\n",
    "    varsHeader = [l.strip('\\n\\r') for l in varsHeader]\n",
    "    varsHeader = np.array(varsHeader)\n",
    "# vars_categories = np.loadtxt(\"../Analsysis Female New/vars_categories.txt\", dtype=str, delimiter='\\n')\n",
    "# vars_categories = np.loadtxt(\"../Analsysis Female New/vars_categories.txt\", dtype=str)\n",
    "\n",
    "with open('../Analsysis Female New/vars_categories.txt') as f:\n",
    "    vars_categories = f.readlines()\n",
    "    vars_categories = [l.strip('\\n\\r') for l in vars_categories]\n",
    "    vars_categories = np.array(vars_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modality</th>\n",
       "      <th>bonf</th>\n",
       "      <th>fdr</th>\n",
       "      <th>dataframe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1L_large_HGL</td>\n",
       "      <td>5.441192</td>\n",
       "      <td>3.425256</td>\n",
       "      <td>idx                                  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T1L_large_SFCN</td>\n",
       "      <td>5.441192</td>\n",
       "      <td>3.113612</td>\n",
       "      <td>idx                                  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T1L_large_SFCN_50b</td>\n",
       "      <td>5.441192</td>\n",
       "      <td>3.159399</td>\n",
       "      <td>idx                                  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T1L_large_SFCN_50b10s</td>\n",
       "      <td>5.441192</td>\n",
       "      <td>3.236979</td>\n",
       "      <td>idx                                  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                modality      bonf       fdr  \\\n",
       "0          T1L_large_HGL  5.441192  3.425256   \n",
       "1         T1L_large_SFCN  5.441192  3.113612   \n",
       "2     T1L_large_SFCN_50b  5.441192  3.159399   \n",
       "3  T1L_large_SFCN_50b10s  5.441192  3.236979   \n",
       "\n",
       "                                           dataframe  \n",
       "0           idx                                  ...  \n",
       "1           idx                                  ...  \n",
       "2           idx                                  ...  \n",
       "3           idx                                  ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = vars_df.iloc[0].dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>names</th>\n",
       "      <th>Categories</th>\n",
       "      <th>pearson_r</th>\n",
       "      <th>t_test_statistic</th>\n",
       "      <th>p_values_corrected</th>\n",
       "      <th>p_values</th>\n",
       "      <th>abs_pearson_r</th>\n",
       "      <th>log_p_values</th>\n",
       "      <th>log_p_values_corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>160</td>\n",
       "      <td>Father still alive (0.0)</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>-0.040368</td>\n",
       "      <td>2.832381</td>\n",
       "      <td>0.261474</td>\n",
       "      <td>0.004639</td>\n",
       "      <td>0.040368</td>\n",
       "      <td>2.333568</td>\n",
       "      <td>0.582572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>182</td>\n",
       "      <td>Age first had sexual intercourse (0.0)</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>-0.050758</td>\n",
       "      <td>3.475740</td>\n",
       "      <td>0.059654</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.050758</td>\n",
       "      <td>3.288972</td>\n",
       "      <td>1.224357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>184</td>\n",
       "      <td>Age first had sexual intercourse (2.0)</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>-0.046285</td>\n",
       "      <td>3.072440</td>\n",
       "      <td>0.172505</td>\n",
       "      <td>0.002136</td>\n",
       "      <td>0.046285</td>\n",
       "      <td>2.670365</td>\n",
       "      <td>0.763199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>186</td>\n",
       "      <td>Lifetime number of sexual partners (0.0)</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>0.054113</td>\n",
       "      <td>3.594708</td>\n",
       "      <td>0.045337</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.054113</td>\n",
       "      <td>3.483710</td>\n",
       "      <td>1.343547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>188</td>\n",
       "      <td>Lifetime number of sexual partners (2.0)</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>0.046755</td>\n",
       "      <td>2.990476</td>\n",
       "      <td>0.201530</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>0.046755</td>\n",
       "      <td>2.552522</td>\n",
       "      <td>0.695661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13233</th>\n",
       "      <td>16845</td>\n",
       "      <td>Operative procedures - OPCS4 (T313 - T31.3 Exc...</td>\n",
       "      <td>Medical History</td>\n",
       "      <td>0.040901</td>\n",
       "      <td>2.900029</td>\n",
       "      <td>0.234121</td>\n",
       "      <td>0.003747</td>\n",
       "      <td>0.040901</td>\n",
       "      <td>2.426261</td>\n",
       "      <td>0.630560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13311</th>\n",
       "      <td>16923</td>\n",
       "      <td>Operative procedures - OPCS4 (U051 - U05.1 Com...</td>\n",
       "      <td>Medical History</td>\n",
       "      <td>0.041120</td>\n",
       "      <td>2.915599</td>\n",
       "      <td>0.227962</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.041120</td>\n",
       "      <td>2.447846</td>\n",
       "      <td>0.642137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13337</th>\n",
       "      <td>16949</td>\n",
       "      <td>Operative procedures - OPCS4 (U211 - U21.1 Mag...</td>\n",
       "      <td>Medical History</td>\n",
       "      <td>0.047614</td>\n",
       "      <td>3.377058</td>\n",
       "      <td>0.078115</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.047614</td>\n",
       "      <td>3.131810</td>\n",
       "      <td>1.107264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13356</th>\n",
       "      <td>16968</td>\n",
       "      <td>Operative procedures - OPCS4 (V256 - V25.6 Pri...</td>\n",
       "      <td>Medical History</td>\n",
       "      <td>0.039548</td>\n",
       "      <td>2.803999</td>\n",
       "      <td>0.273305</td>\n",
       "      <td>0.005067</td>\n",
       "      <td>0.039548</td>\n",
       "      <td>2.295275</td>\n",
       "      <td>0.563353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13484</th>\n",
       "      <td>17096</td>\n",
       "      <td>Operative procedures - OPCS4 (W843 - W84.3 End...</td>\n",
       "      <td>Medical History</td>\n",
       "      <td>0.038195</td>\n",
       "      <td>2.707922</td>\n",
       "      <td>0.326871</td>\n",
       "      <td>0.006794</td>\n",
       "      <td>0.038195</td>\n",
       "      <td>2.167904</td>\n",
       "      <td>0.485623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         idx                                              names  \\\n",
       "132      160                           Father still alive (0.0)   \n",
       "149      182             Age first had sexual intercourse (0.0)   \n",
       "151      184             Age first had sexual intercourse (2.0)   \n",
       "152      186           Lifetime number of sexual partners (0.0)   \n",
       "154      188           Lifetime number of sexual partners (2.0)   \n",
       "...      ...                                                ...   \n",
       "13233  16845  Operative procedures - OPCS4 (T313 - T31.3 Exc...   \n",
       "13311  16923  Operative procedures - OPCS4 (U051 - U05.1 Com...   \n",
       "13337  16949  Operative procedures - OPCS4 (U211 - U21.1 Mag...   \n",
       "13356  16968  Operative procedures - OPCS4 (V256 - V25.6 Pri...   \n",
       "13484  17096  Operative procedures - OPCS4 (W843 - W84.3 End...   \n",
       "\n",
       "            Categories  pearson_r  t_test_statistic  p_values_corrected  \\\n",
       "132          Lifestyle  -0.040368          2.832381            0.261474   \n",
       "149          Lifestyle  -0.050758          3.475740            0.059654   \n",
       "151          Lifestyle  -0.046285          3.072440            0.172505   \n",
       "152          Lifestyle   0.054113          3.594708            0.045337   \n",
       "154          Lifestyle   0.046755          2.990476            0.201530   \n",
       "...                ...        ...               ...                 ...   \n",
       "13233  Medical History   0.040901          2.900029            0.234121   \n",
       "13311  Medical History   0.041120          2.915599            0.227962   \n",
       "13337  Medical History   0.047614          3.377058            0.078115   \n",
       "13356  Medical History   0.039548          2.803999            0.273305   \n",
       "13484  Medical History   0.038195          2.707922            0.326871   \n",
       "\n",
       "       p_values  abs_pearson_r  log_p_values  log_p_values_corrected  \n",
       "132    0.004639       0.040368      2.333568                0.582572  \n",
       "149    0.000514       0.050758      3.288972                1.224357  \n",
       "151    0.002136       0.046285      2.670365                0.763199  \n",
       "152    0.000328       0.054113      3.483710                1.343547  \n",
       "154    0.002802       0.046755      2.552522                0.695661  \n",
       "...         ...            ...           ...                     ...  \n",
       "13233  0.003747       0.040901      2.426261                0.630560  \n",
       "13311  0.003566       0.041120      2.447846                0.642137  \n",
       "13337  0.000738       0.047614      3.131810                1.107264  \n",
       "13356  0.005067       0.039548      2.295275                0.563353  \n",
       "13484  0.006794       0.038195      2.167904                0.485623  \n",
       "\n",
       "[345 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.log_p_values > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.log_p_values > 5.441192])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modality</th>\n",
       "      <th>bonf</th>\n",
       "      <th>fdr</th>\n",
       "      <th>dataframe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1L_large_HGL</td>\n",
       "      <td>5.441192</td>\n",
       "      <td>3.425256</td>\n",
       "      <td>idx                                  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T1L_large_SFCN</td>\n",
       "      <td>5.441192</td>\n",
       "      <td>3.113612</td>\n",
       "      <td>idx                                  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T1L_large_SFCN_50b</td>\n",
       "      <td>5.441192</td>\n",
       "      <td>3.159399</td>\n",
       "      <td>idx                                  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T1L_large_SFCN_50b10s</td>\n",
       "      <td>5.441192</td>\n",
       "      <td>3.236979</td>\n",
       "      <td>idx                                  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                modality      bonf       fdr  \\\n",
       "0          T1L_large_HGL  5.441192  3.425256   \n",
       "1         T1L_large_SFCN  5.441192  3.113612   \n",
       "2     T1L_large_SFCN_50b  5.441192  3.159399   \n",
       "3  T1L_large_SFCN_50b10s  5.441192  3.236979   \n",
       "\n",
       "                                           dataframe  \n",
       "0           idx                                  ...  \n",
       "1           idx                                  ...  \n",
       "2           idx                                  ...  \n",
       "3           idx                                  ...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276179.8567397032"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(10, 5.441192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.35066666666666"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "276200 / 5000 * 2 * 345 / 3600 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1431074074074075"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "276200 / 5000 * 2 * 1676 / 3600 / 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_to_be_ignored = [21269692]\n",
    "subject_sex = 'female'\n",
    "prototype_flag = True\n",
    "\n",
    "deconfound_flag = True\n",
    "vars_cutoff_nan = 0.1\n",
    "\n",
    "# Identify Correct File to Load\n",
    "\n",
    "IDP_file = '../Analsysis Female New/female_test_IDPs.h5'\n",
    "confounds_file = '../Analsysis Female New/female_test_conf12.h5'\n",
    "data_file = 'female_test.pkl'\n",
    "\n",
    "confounds = h5py.File(confounds_file, 'r')\n",
    "confounds = confounds['conf12'][()]\n",
    "\n",
    "IDP_h5 = h5py.File(IDP_file, 'r')\n",
    "subjects_h5 = IDP_h5['subjects'][()]\n",
    "\n",
    "# Load the relevant dataframe based on the required modality\n",
    "\n",
    "df = pd.read_pickle(data_file)\n",
    "\n",
    "IDP_h5 = h5py.File(IDP_file, 'r')\n",
    "vars_i_deconf = IDP_h5['vars_i_deconf'][()]\n",
    "subjects_h5 = IDP_h5['subjects'][()]\n",
    "\n",
    "with open('../Analsysis Female New/varsHeader.txt') as f:\n",
    "    varsHeader = f.readlines()\n",
    "    varsHeader = [l.strip('\\n\\r') for l in varsHeader]\n",
    "    varsHeader = np.array(varsHeader)\n",
    "with open('../Analsysis Female New/vars_categories.txt') as f:\n",
    "    vars_categories = f.readlines()\n",
    "    vars_categories = [l.strip('\\n\\r') for l in vars_categories]\n",
    "    vars_categories = np.array(vars_categories)\n",
    "\n",
    "varsIDX = np.arange(0, len(varsHeader), 1).astype(int)\n",
    "\n",
    "vars_perc_not_nan = np.sum(np.isnan(vars_i_deconf)==False,axis=0) / vars_i_deconf.shape[0]\n",
    "vars_idx_nan_cutoff = np.where(vars_perc_not_nan >= vars_cutoff_nan)[0]\n",
    "\n",
    "varsHeader_subset = varsHeader[vars_idx_nan_cutoff]\n",
    "vars_i_deconf_subset = vars_i_deconf[:, vars_idx_nan_cutoff]\n",
    "vars_categories_subset = vars_categories[vars_idx_nan_cutoff]\n",
    "varsIDX_subset = varsIDX[vars_idx_nan_cutoff]\n",
    "\n",
    "del IDP_h5\n",
    "\n",
    "vars_corrs = []\n",
    "vars_mods = []\n",
    "vars_bnf_thrs = []\n",
    "vars_fdr_thrs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5021, 13809)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_i_deconf_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 17516, 17525, 17526])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varsIDX_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "varsIDX_interest = df[df.log_p_values > 2].idx.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  160,   182,   184,   186,   188,   418,   430,   704,   754,\n",
       "         805,  1204,  1209,  1454,  1517,  1552,  1656,  1657,  1659,\n",
       "        1817,  1866,  1942,  2024,  2027,  2059,  2075,  2225,  2301,\n",
       "        2394,  2421,  2613,  2729,  2778,  2780,  2796,  2798,  2812,\n",
       "        2844,  2865,  2870,  2873,  2922,  3019,  3021,  3036,  3048,\n",
       "        3050,  3052,  3060,  3152,  3164,  3166,  3167,  3183,  3185,\n",
       "        3187,  3189,  3191,  3218,  3220,  3222,  3224,  3230,  3231,\n",
       "        3233,  3235,  3237,  3243,  3245,  3248,  3250,  3252,  3254,\n",
       "        3259,  3261,  3264,  3270,  3272,  3274,  3278,  3281,  3285,\n",
       "        3291,  3295,  3305,  3314,  3316,  3318,  3320,  3322,  3324,\n",
       "        3330,  3331,  3332,  3334,  3336,  3338,  3340,  3347,  3354,\n",
       "        3375,  3377,  3379,  3380,  3382,  3384,  3386,  3388,  3390,\n",
       "        3392,  3396,  3398,  3400,  3401,  3402,  3404,  3406,  3408,\n",
       "        3410,  3412,  3414,  3416,  3418,  3420,  3422,  3424,  3426,\n",
       "        3428,  3430,  3434,  3436,  3440,  3442,  3444,  3446,  3448,\n",
       "        3456,  3460,  3462,  3464,  3468,  3504,  3505,  3508,  3512,\n",
       "        3513,  3514,  3515,  3521,  4229,  4328,  4385,  4533,  4583,\n",
       "        4618,  4830,  4964,  5139,  5432,  5582,  6113,  6116,  6340,\n",
       "        6696,  6936,  6943,  7064,  7133,  7153,  7156,  7171,  7173,\n",
       "        7216,  7257,  7558,  7566,  7616,  7618,  7689,  7802,  7899,\n",
       "        7903,  7925,  8046,  8050,  8058,  8106,  8137,  8141,  8155,\n",
       "        8252,  8284,  8411,  8433,  8455,  8516,  8563,  8566,  8599,\n",
       "        8607,  8616,  8634,  8637,  8641,  8717,  8724,  8760,  8781,\n",
       "        8923,  9021,  9036,  9146,  9232,  9252,  9329,  9451,  9590,\n",
       "        9717,  9798,  9818,  9868,  9959, 10047, 10185, 10221, 10255,\n",
       "       10368, 10417, 10611, 10737, 10843, 10900, 10926, 10990, 11021,\n",
       "       11051, 11063, 11066, 11159, 11163, 11392, 11442, 11467, 11489,\n",
       "       11512, 11544, 11548, 11653, 11673, 11724, 11732, 11751, 11850,\n",
       "       11880, 11918, 11977, 11982, 11987, 12008, 12055, 12056, 12081,\n",
       "       12083, 12414, 12473, 12476, 12612, 12674, 12737, 12772, 12806,\n",
       "       12860, 12861, 12939, 12961, 13255, 13331, 13347, 13413, 13519,\n",
       "       13586, 13588, 13622, 13691, 13719, 13783, 13927, 13951, 13952,\n",
       "       14000, 14138, 14199, 14251, 14285, 14303, 14311, 14331, 14352,\n",
       "       14549, 14611, 14629, 14678, 14679, 14763, 14804, 14830, 14894,\n",
       "       14951, 14961, 14980, 15060, 15073, 15096, 15158, 15200, 15262,\n",
       "       15264, 15361, 15415, 15481, 15484, 15531, 15609, 15635, 15707,\n",
       "       15714, 15772, 15792, 15970, 16109, 16110, 16124, 16333, 16342,\n",
       "       16514, 16539, 16653, 16656, 16704, 16720, 16795, 16845, 16923,\n",
       "       16949, 16968, 17096])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varsIDX_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varsIDX_interest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5021, 13809)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_i_deconf_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13809,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varsIDX_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([132]),)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = varsIDX_interest[0]\n",
    "np.where(varsIDX_subset==a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([160])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varsIDX_subset[np.where(varsIDX_subset==a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.29583353,         nan,         nan, ...,         nan,\n",
       "       -0.52333289, -0.50139622])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_i_deconf_subset[np.where(varsIDX_subset==a)[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# varsHeader_subset = varsHeader[vars_idx_nan_cutoff]\n",
    "# vars_i_deconf_subset = vars_i_deconf[:, vars_idx_nan_cutoff]\n",
    "# vars_categories_subset = vars_categories[vars_idx_nan_cutoff]\n",
    "# varsIDX_subset = varsIDX[vars_idx_nan_cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Father still alive (0.0)'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varsHeader_subset[np.where(varsIDX_subset==a)[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.29583353,         nan,         nan, ...,         nan,\n",
       "       -0.52333289, -0.50139622])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_i_deconf_subset[np.where(varsIDX_subset==a)[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lifestyle'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_categories_subset[np.where(varsIDX_subset==a)[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varsIDX_subset[np.where(varsIDX_subset==a)[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345\n",
      "467\n",
      "441\n",
      "423\n",
      "1676\n"
     ]
    }
   ],
   "source": [
    "sm = 0\n",
    "\n",
    "for idx in range(4):\n",
    "    df = vars_df.iloc[idx].dataframe\n",
    "    varsIDX_interest = df[df.log_p_values > 2].idx.values\n",
    "\n",
    "    print(len(varsIDX_interest))\n",
    "    sm += len(varsIDX_interest)\n",
    "    \n",
    "    varsHeader_subset2 = []\n",
    "    vars_i_deconf_subset2 = []\n",
    "    vars_categories_subset2 = []\n",
    "    varsIDX_subset2 = []\n",
    "\n",
    "    for item in varsIDX_interest:\n",
    "        varsHeader_subset2.append(varsHeader_subset[np.where(varsIDX_subset==item)[0][0]])\n",
    "        vars_i_deconf_subset2.append(vars_i_deconf_subset[:, np.where(varsIDX_subset==item)[0][0]])\n",
    "        vars_categories_subset2.append(vars_categories_subset[np.where(varsIDX_subset==item)[0][0]])\n",
    "        varsIDX_subset2.append(varsIDX_subset[np.where(varsIDX_subset==item)[0][0]])\n",
    "    \n",
    "    filename = 'logpOver2_' + str(idx) + '.npz'\n",
    "    \n",
    "    np.savez(filename, np.array(varsHeader_subset2), np.array(vars_i_deconf_subset2),\n",
    "        np.array(vars_categories_subset2), np.array(varsIDX_subset2))\n",
    "    \n",
    "print(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(varsIDX_subset2) == varsIDX_interest).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5050"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(varsIDX_subset==item)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13809,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varsIDX_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('logpOver2.npz', np.array(varsHeader_subset2), np.array(vars_i_deconf_subset2),\n",
    "        np.array(vars_categories_subset2), np.array(varsIDX_subset2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load('logpOver2.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arr_0', 'arr_1', 'arr_2', 'arr_3']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npzfile.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Father still alive (0.0)',\n",
       "       'Age first had sexual intercourse (0.0)',\n",
       "       'Age first had sexual intercourse (2.0)',\n",
       "       'Lifetime number of sexual partners (0.0)',\n",
       "       'Lifetime number of sexual partners (2.0)',\n",
       "       'Attendance/disability/mobility allowance (2.0)',\n",
       "       'Leisure/social activities (2.1)',\n",
       "       'Time spent outdoors in winter (2.0)', 'Nap during day (0.0)',\n",
       "       'Types of transport used (excluding work) (1.0)',\n",
       "       'Never eat eggs, dairy, wheat, sugar (0.0)',\n",
       "       'Never eat eggs, dairy, wheat, sugar (2.0)',\n",
       "       'Type of yogurt eaten (2.0)', 'Englyst dietary fibre (2.0)',\n",
       "       'Magnesium (2.0)', 'Added milk to instant coffee (1.0)',\n",
       "       'Added milk to instant coffee (2.0)',\n",
       "       'Added milk to instant coffee (4.0)', 'Oat crunch intake (2.0)',\n",
       "       'Type milk consumed (1.0)',\n",
       "       'Number of crackers/crispbreads with butter/margarine (2.0)',\n",
       "       'Dessert consumers (1.0)', 'Dessert consumers (4.0)',\n",
       "       'Sponge pudding intake (1.0)', 'Sweet snack consumers (2.0)',\n",
       "       'Wholemeal pasta intake (1.0)', 'Mozzarella intake (4.0)',\n",
       "       'Fat removed from meat (2.0)', 'Breaded fish intake (4.0)',\n",
       "       'Onion intake (1.0)', 'Mango intake (1.0)',\n",
       "       'Alcohol intake frequency. (0.0)',\n",
       "       'Alcohol intake frequency. (2.0)',\n",
       "       'Average weekly spirits intake (2.0)',\n",
       "       'Average weekly fortified wine intake (0.0)',\n",
       "       'Reason for reducing amount of alcohol drunk (2.0)',\n",
       "       'Average weekly intake of other alcoholic drinks (0.0)',\n",
       "       'Amount of alcohol drunk on a typical drinking day (0.0)',\n",
       "       'Frequency of memory loss due to drinking alcohol in last year (0.0)',\n",
       "       'Frequency of drinking alcohol (0.0)',\n",
       "       'Past tobacco smoking (2.0)', 'Smoking status (0.0)',\n",
       "       'Smoking status (2.0)', 'Age of stopping smoking (0.0)',\n",
       "       'Waist circumference (2.0)', 'Hip circumference (0.0)',\n",
       "       'Hip circumference (2.0)', 'Seated height (2.0)',\n",
       "       'Weight (pre-imaging) (2.0)', 'Body mass index (BMI) (0.0)',\n",
       "       'Body mass index (BMI) (2.0)', 'Weight (0.0)',\n",
       "       'Body surface area (2.0)', 'Body fat percentage (0.0)',\n",
       "       'Body fat percentage (2.0)', 'Whole body fat mass (0.0)',\n",
       "       'Whole body fat mass (2.0)', 'Leg fat percentage (right) (0.0)',\n",
       "       'Leg fat percentage (right) (2.0)', 'Leg fat mass (right) (0.0)',\n",
       "       'Leg fat mass (right) (2.0)', 'Leg fat percentage (left) (2.0)',\n",
       "       'Arm fat percentage (right) (0.0)',\n",
       "       'Arm fat percentage (right) (2.0)', 'Arm fat mass (right) (0.0)',\n",
       "       'Arm fat mass (right) (2.0)', 'Arm fat percentage (left) (0.0)',\n",
       "       'Arm fat percentage (left) (2.0)', 'Trunk fat percentage (0.0)',\n",
       "       'Trunk fat percentage (2.0)', 'Trunk fat mass (0.0)',\n",
       "       'Trunk fat mass (2.0)', 'Android tissue fat percentage (2.0)',\n",
       "       'Android total mass (2.0)',\n",
       "       'Arm tissue fat percentage (left) (2.0)',\n",
       "       'Arms tissue fat percentage (2.0)', 'Arms total mass (2.0)',\n",
       "       'Gynoid bone mass (2.0)', 'Gynoid total mass (2.0)',\n",
       "       'Leg total mass (right) (2.0)', 'Legs total mass (2.0)',\n",
       "       'Total mass (2.0)', 'Trunk total mass (2.0)',\n",
       "       'Heel Broadband ultrasound attenuation, direct entry (0.0)',\n",
       "       'Heel broadband ultrasound attenuation (left) (0.0)',\n",
       "       'Heel broadband ultrasound attenuation (left) (2.0)',\n",
       "       'Speed of sound through heel (left) (0.0)',\n",
       "       'Speed of sound through heel (left) (2.0)',\n",
       "       'Heel quantitative ultrasound index (QUI), direct entry (left) (0.0)',\n",
       "       'Heel quantitative ultrasound index (QUI), direct entry (left) (2.0)',\n",
       "       'Heel broadband ultrasound attenuation (right) (0.0)',\n",
       "       'Heel broadband ultrasound attenuation (right) (1.0)',\n",
       "       'Heel broadband ultrasound attenuation (right) (2.0)',\n",
       "       'Speed of sound through heel (right) (0.0)',\n",
       "       'Speed of sound through heel (right) (2.0)',\n",
       "       'Heel quantitative ultrasound index (QUI), direct entry (right) (0.0)',\n",
       "       'Heel quantitative ultrasound index (QUI), direct entry (right) (2.0)',\n",
       "       'Heel quantitative ultrasound index (QUI), manual entry (left) (2.0)',\n",
       "       'Speed of sound through heel, manual entry (left) (2.0)',\n",
       "       'L1-L4 BMC (bone mineral content) (2.0)',\n",
       "       'L1-L4 BMD (bone mineral density) (2.0)',\n",
       "       'Femur lower neck BMD (bone mineral density) (right) (2.0)',\n",
       "       'Femur neck BMD (bone mineral density) (right) (2.0)',\n",
       "       'Femur neck BMD (bone mineral density) T-score (right) (2.0)',\n",
       "       'Femur shaft BMD (bone mineral density) (right) (2.0)',\n",
       "       'Femur total BMD (bone mineral density) (right) (2.0)',\n",
       "       'Femur total BMD (bone mineral density) T-score (right) (2.0)',\n",
       "       'Femur troch BMD (bone mineral density) (right) (2.0)',\n",
       "       'Femur troch BMD (bone mineral density) T-score (right) (2.0)',\n",
       "       'Femur wards BMD (bone mineral density) (right) (2.0)',\n",
       "       'Femur wards BMD (bone mineral density) T-score (right) (2.0)',\n",
       "       'Arm BMD (bone mineral density) (left) (2.0)',\n",
       "       'Arm BMD (bone mineral density) (right) (2.0)',\n",
       "       'Arms BMC (bone mineral content) (2.0)',\n",
       "       'Arms BMD (bone mineral density) (2.0)',\n",
       "       'Head BMD (bone mineral density) (2.0)',\n",
       "       'Legs BMC (bone mineral content) (2.0)',\n",
       "       'Legs BMD (bone mineral density) (2.0)',\n",
       "       'Pelvis BMD (bone mineral density) (2.0)',\n",
       "       'Ribs BMD (bone mineral density) (2.0)',\n",
       "       'Spine BMD (bone mineral density) (2.0)',\n",
       "       'Total BMC (bone mineral content) (2.0)',\n",
       "       'Total BMD (bone mineral density) (2.0)',\n",
       "       'Total BMD (bone mineral density) T-score (2.0)',\n",
       "       'Trunk BMC (bone mineral content) (2.0)',\n",
       "       'Trunk BMD (bone mineral density) (2.0)',\n",
       "       'Femur shaft BMD (bone mineral density) (left) (2.0)',\n",
       "       'Femur total BMD (bone mineral density) (left) (2.0)',\n",
       "       'Femur total BMD (bone mineral density) T-score (left) (2.0)',\n",
       "       'Femur troch BMD (bone mineral density) (left) (2.0)',\n",
       "       'Femur wards BMD (bone mineral density) (left) (2.0)',\n",
       "       'Femur troch BMD (bone mineral density) T-score (left) (2.0)',\n",
       "       'Femur neck BMD (bone mineral density) (left) (2.0)',\n",
       "       'Femur neck BMD (bone mineral density) T-score (left) (2.0)',\n",
       "       'Femur wards BMD (bone mineral density) T-score (left) (2.0)',\n",
       "       'Head BMC (bone mineral content) (2.0)',\n",
       "       'Pelvis BMC (bone mineral content) (2.0)', 'Ribs bone area (2.0)',\n",
       "       'Ribs BMC (bone mineral content) (2.0)',\n",
       "       'Spine BMC (bone mineral content) (2.0)',\n",
       "       'Diastolic blood pressure, automated reading (0.0)',\n",
       "       'Diastolic blood pressure, automated reading (0.1)',\n",
       "       'Diastolic blood pressure, automated reading (2.0)',\n",
       "       'Systolic blood pressure, automated reading (0.0)',\n",
       "       'Systolic blood pressure, automated reading (0.1)',\n",
       "       'Systolic blood pressure, automated reading (1.0)',\n",
       "       'Systolic blood pressure, automated reading (1.1)',\n",
       "       'Pulse rate (1.0)', 'Diastolic brachial blood pressure (2.0)',\n",
       "       'Signal-to-noise-ratio (SNR) of triplet (left) (2.12)',\n",
       "       'Triplet correct (left) (2.11)',\n",
       "       'Time to press last digit (left) (2.15)',\n",
       "       \"Time to press 'next' (left) (2.15)\",\n",
       "       \"Number of times 'clear' was pressed (left) (1.10)\",\n",
       "       'Time to press first digit (right) (2.9)',\n",
       "       \"Number of times 'clear' was pressed (right) (0.9)\",\n",
       "       '6mm weak meridian angle (right) (0.2)',\n",
       "       'Number of rounds to result (left) (0.0)', 'Bicycle speed (1.6)',\n",
       "       'Mean corpuscular volume (0.0)',\n",
       "       'Mean corpuscular haemoglobin (0.0)',\n",
       "       'Index for card B in round (1.2)', 'Value entered (2.6)',\n",
       "       'Interval between previous point and current one in alphanumeric path (trail #2) (2.5)',\n",
       "       'Interval between previous point and current one in alphanumeric path (trail #2) (2.12)',\n",
       "       'Time to complete round (0.0)',\n",
       "       'Interval between previous point and current one in numeric path (trail #1) (0.15)',\n",
       "       'Interval between previous point and current one in alphanumeric path (trail #2) (0.7)',\n",
       "       'Interval between previous point and current one in alphanumeric path (trail #2) (0.10)',\n",
       "       'Interval between previous point and current one in alphanumeric path (trail #2) (0.25)',\n",
       "       'Duration to complete alphanumeric path (trail #2) (0.0)',\n",
       "       'Values wanted (0.28)', 'Values entered (0.28)',\n",
       "       'Number of treatments/medications taken (2.0)',\n",
       "       'Long-standing illness, disability or infirmity (2.0)',\n",
       "       'Diabetes diagnosed by doctor (0.0)',\n",
       "       'Diabetes diagnosed by doctor (2.0)',\n",
       "       'Back pain for 3+ months (2.0)',\n",
       "       'Leg pain when walking normally (2.0)',\n",
       "       'Vascular/heart problems diagnosed by doctor (-7.0 - None of the above)',\n",
       "       'Vascular/heart problems diagnosed by doctor (4 - High blood pressure)',\n",
       "       'Medication for cholesterol, blood pressure, diabetes, or take exogenous hormones (2.0)',\n",
       "       'Non-cancer illness code, self-reported (1065 - hypertension)',\n",
       "       'Non-cancer illness code, self-reported (1073 - gestational hypertension/pre-eclampsia)',\n",
       "       'Non-cancer illness code, self-reported (1081 - stroke)',\n",
       "       'Non-cancer illness code, self-reported (1220 - diabetes)',\n",
       "       'Non-cancer illness code, self-reported (1266 - head injury)',\n",
       "       'Non-cancer illness code, self-reported (1276 - diabetic eye disease)',\n",
       "       'Non-cancer illness code, self-reported (1295 - joint disorder)',\n",
       "       'Non-cancer illness code, self-reported (1473 - high cholesterol)',\n",
       "       'Non-cancer illness code, self-reported (1512 - umbilical hernia)',\n",
       "       'Non-cancer illness code, self-reported (1663 - abnormal smear (cervix))',\n",
       "       \"Treatment/medication code (1201 - st john's wort/hypericum [ctsu])\",\n",
       "       'Treatment/medication code (1140860806 - ramipril)',\n",
       "       'Treatment/medication code (1140864992 - tramadol)',\n",
       "       'Treatment/medication code (1140868080 - cyclizine)',\n",
       "       'Treatment/medication code (1140868226 - aspirin)',\n",
       "       'Treatment/medication code (1140869848 - methotrexate)',\n",
       "       'Treatment/medication code (1140870422 - folic acid product)',\n",
       "       'Treatment/medication code (1140871024 - vitamin b compound tablet)',\n",
       "       'Treatment/medication code (1140871732 - buprenorphine)',\n",
       "       'Treatment/medication code (1140872072 - tegretol 100mg tablet)',\n",
       "       'Treatment/medication code (1140872198 - sodium valproate)',\n",
       "       'Treatment/medication code (1140879644 - amantadine)',\n",
       "       'Treatment/medication code (1140879802 - amlodipine)',\n",
       "       'Treatment/medication code (1140883066 - insulin product)',\n",
       "       'Treatment/medication code (1140884600 - metformin)',\n",
       "       'Treatment/medication code (1141146234 - atorvastatin)',\n",
       "       'Treatment/medication code (1141171932 - levetiracetam)',\n",
       "       'Treatment/medication code (1141173872 - cetraben cream)',\n",
       "       'Treatment/medication code (2038459814 - digoxin)',\n",
       "       'Operation code (1470 - spinal cord surgery)',\n",
       "       'Operation code (1493 - arthroscopy nos)',\n",
       "       'Operation code (1590 - spinal fusion)',\n",
       "       'Interpolated Age of participant when non-cancer illness first diagnosed (2.1)',\n",
       "       'Average number of times bowels opened per day (0.0)',\n",
       "       'Type of cancer: ICD10 (C56 - C56 Malignant neoplasm of ovary)',\n",
       "       'Type of cancer: ICD9 (1727 - 1727 Malignant melanoma of lower limb, including hip)',\n",
       "       'Records in HES inpatient operations dataset (0.0)',\n",
       "       'Operative procedures - main OPCS4 (B295 - B29.5 Revision of reconstruction of breast)',\n",
       "       'Operative procedures - main OPCS4 (C855 - C85.5 Retinopexy NEC)',\n",
       "       'Operative procedures - main OPCS4 (F093 - F09.3 Surgical removal of wisdom tooth NEC)',\n",
       "       'Operative procedures - main OPCS4 (J539 - J53.9 Unspecified endoscopic ultrasound examination of bile duct)',\n",
       "       'Operative procedures - main OPCS4 (K751 - K75.1 Percutaneous transluminal balloon angioplasty and insertion of 1-2 drug-eluting stents into coronary artery)',\n",
       "       'Operative procedures - main OPCS4 (L943 - L94.3 Percutaneous transluminal insertion of subcutaneous port)',\n",
       "       'Operative procedures - main OPCS4 (Q013 - Q01.3 Excision of lesion of cervix uteri)',\n",
       "       'Operative procedures - main OPCS4 (Q353 - Q35.3 Endoscopic bilateral ringing of fallopian tubes)',\n",
       "       'Operative procedures - main OPCS4 (U293 - U29.3 Glucose tolerance test)',\n",
       "       'Operative procedures - main OPCS4 (W844 - W84.4 Endoscopic decompression of joint)',\n",
       "       'External causes - ICD10 (V184 - V18.4 Driver injured in traffic accident)',\n",
       "       'External causes - ICD10 (W259 - W25.9 Unspecified place)',\n",
       "       'External causes - ICD10 (X509 - X50.9 Unspecified place)',\n",
       "       'Diagnoses - main ICD10 (D120 - D12.0 Caecum)',\n",
       "       'Diagnoses - main ICD10 (G35 - G35 Multiple sclerosis)',\n",
       "       'Diagnoses - main ICD10 (I447 - I44.7 Left bundle-branch block, unspecified)',\n",
       "       'Diagnoses - main ICD10 (I849 - I84.9 Unspecified haemorrhoids without complication)',\n",
       "       'Diagnoses - main ICD10 (J322 - J32.2 Chronic ethmoidal sinusitis)',\n",
       "       'Diagnoses - main ICD10 (M7965 - M79.65 Pain in limb (Pelvic region and thigh))',\n",
       "       'Diagnoses - main ICD10 (N200 - N20.0 Calculus of kidney)',\n",
       "       'Diagnoses - secondary ICD10 (D128 - D12.8 Rectum)',\n",
       "       'Diagnoses - secondary ICD10 (D685 - D68.5 Primary Thrombophilia)',\n",
       "       'Diagnoses - secondary ICD10 (E109 - E10.9 Without complications)',\n",
       "       'Diagnoses - secondary ICD10 (E782 - E78.2 Mixed hyperlipidaemia)',\n",
       "       \"Diagnoses - secondary ICD10 (F009 - F00.9 Dementia in Alzheimer's disease, unspecified)\",\n",
       "       \"Diagnoses - secondary ICD10 (G309 - G30.9 Alzheimer's disease, unspecified)\",\n",
       "       'Diagnoses - secondary ICD10 (G403 - G40.3 Generalised idiopathic epilepsy and epileptic syndromes)',\n",
       "       'Diagnoses - secondary ICD10 (H653 - H65.3 Chronic mucoid otitis media)',\n",
       "       'Diagnoses - secondary ICD10 (I10 - I10 Essential (primary) hypertension)',\n",
       "       'Diagnoses - secondary ICD10 (I489 - I48.9 Atrial fibrillation and atrial flutter,  unspecified)',\n",
       "       'Diagnoses - secondary ICD10 (I500 - I50.0 Congestive heart failure)',\n",
       "       \"Diagnoses - secondary ICD10 (I730 - I73.0 Raynaud's syndrome)\",\n",
       "       'Diagnoses - secondary ICD10 (K228 - K22.8 Other specified diseases of oesophagus)',\n",
       "       'Diagnoses - secondary ICD10 (K469 - K46.9 Unspecified abdominal hernia without obstruction or gangrene)',\n",
       "       'Diagnoses - secondary ICD10 (K635 - K63.5 Polyp of colon)',\n",
       "       'Diagnoses - secondary ICD10 (L270 - L27.0 Generalised skin eruption due to drugs and medicaments)',\n",
       "       'Diagnoses - secondary ICD10 (L409 - L40.9 Psoriasis, unspecified)',\n",
       "       'Diagnoses - secondary ICD10 (L570 - L57.0 Actinic keratosis)',\n",
       "       'Diagnoses - secondary ICD10 (L989 - L98.9 Disorder of skin and subcutaneous tissue, unspecified)',\n",
       "       'Diagnoses - secondary ICD10 (M2116 - M21.16 Varus deformity, not elsewhere classified (Lower leg))',\n",
       "       'Diagnoses - secondary ICD10 (M2126 - M21.26 Flexion deformity (Lower leg))',\n",
       "       'Diagnoses - secondary ICD10 (M255 - M25.5 Pain in joint)',\n",
       "       'Diagnoses - secondary ICD10 (M2551 - M25.51 Pain in joint (Shoulder region))',\n",
       "       'Diagnoses - secondary ICD10 (R11 - R11 Nausea and vomiting)',\n",
       "       'Diagnoses - secondary ICD10 (R521 - R52.1 Chronic intractable pain)',\n",
       "       'Diagnoses - secondary ICD10 (R53 - R53 Malaise and fatigue)',\n",
       "       'Diagnoses - secondary ICD10 (U838 - U83.8 Resistance to other single specified antibiotic)',\n",
       "       'Diagnoses - secondary ICD10 (Z302 - Z30.2 Sterilisation)',\n",
       "       'Diagnoses - secondary ICD10 (Z803 - Z80.3 Family history of malignant neoplasm of breast)',\n",
       "       'Diagnoses - secondary ICD10 (Z867 - Z86.7 Personal history of diseases of the circulatory system)',\n",
       "       'Diagnoses - secondary ICD10 (Z922 - Z92.2 Personal history of long-term (current) use of other medicaments)',\n",
       "       'Operative procedures - secondary OPCS4 (A842 - A84.2 Electromyography)',\n",
       "       'Operative procedures - secondary OPCS4 (A843 - A84.3 Nerve conduction studies)',\n",
       "       'Operative procedures - secondary OPCS4 (D151 - D15.1 Myringotomy with insertion of ventilation tube through tympanic membrane)',\n",
       "       'Operative procedures - secondary OPCS4 (E142 - E14.2 Intranasal ethmoidectomy)',\n",
       "       'Operative procedures - secondary OPCS4 (S473 - S47.3 Incision of lesion of skin of head or neck)',\n",
       "       'Operative procedures - secondary OPCS4 (U051 - U05.1 Computed tomography of head)',\n",
       "       'Operative procedures - secondary OPCS4 (U211 - U21.1 Magnetic resonance imaging NEC)',\n",
       "       'Operative procedures - secondary OPCS4 (W843 - W84.3 Endoscopic division of synovial plica)',\n",
       "       'Operative procedures - secondary OPCS4 (Y141 - Y14.1 Insertion of expanding covered metal stent into organ NOC)',\n",
       "       'Operative procedures - secondary OPCS4 (Y532 - Y53.2 Approach to organ under ultrasonic control)',\n",
       "       'Operative procedures - secondary OPCS4 (Y534 - Y53.4 Approach to organ under fluoroscopic control)',\n",
       "       'Operative procedures - secondary OPCS4 (Y761 - Y76.1 Functional endoscopic sinus surgery)',\n",
       "       'Operative procedures - secondary OPCS4 (Z154 - Z15.4 Lower outer quadrant of breast)',\n",
       "       'Operative procedures - secondary OPCS4 (Z282 - Z28.2 Caecum)',\n",
       "       'Operative procedures - secondary OPCS4 (Z502 - Z50.2 Skin of hand)',\n",
       "       'Operative procedures - secondary OPCS4 (Z894 - Z89.4 Hand NEC)',\n",
       "       'Operative procedures - secondary OPCS4 (Z941 - Z94.1 Bilateral operation)',\n",
       "       'Operative procedures - secondary OPCS4 (Z942 - Z94.2 Right sided operation)',\n",
       "       'Records in HES inpatient diagnoses dataset (0.0)',\n",
       "       'Diagnoses - ICD10 (C501 - C50.1 Central portion of breast)',\n",
       "       'Diagnoses - ICD10 (D123 - D12.3 Transverse colon)',\n",
       "       'Diagnoses - ICD10 (D329 - D32.9 Meninges, unspecified)',\n",
       "       'Diagnoses - ICD10 (D685 - D68.5 Primary Thrombophilia)',\n",
       "       'Diagnoses - ICD10 (E050 - E05.0 Thyrotoxicosis with diffuse goitre)',\n",
       "       'Diagnoses - ICD10 (E109 - E10.9 Without complications)',\n",
       "       'Diagnoses - ICD10 (E782 - E78.2 Mixed hyperlipidaemia)',\n",
       "       \"Diagnoses - ICD10 (F009 - F00.9 Dementia in Alzheimer's disease, unspecified)\",\n",
       "       'Diagnoses - ICD10 (I10 - I10 Essential (primary) hypertension)',\n",
       "       'Diagnoses - ICD10 (I500 - I50.0 Congestive heart failure)',\n",
       "       \"Diagnoses - ICD10 (I730 - I73.0 Raynaud's syndrome)\",\n",
       "       'Diagnoses - ICD10 (J322 - J32.2 Chronic ethmoidal sinusitis)',\n",
       "       'Diagnoses - ICD10 (J324 - J32.4 Chronic pansinusitis)',\n",
       "       'Diagnoses - ICD10 (K298 - K29.8 Duodenitis)',\n",
       "       'Diagnoses - ICD10 (K573 - K57.3 Diverticular disease of large intestine without perforation or abscess)',\n",
       "       'Diagnoses - ICD10 (K635 - K63.5 Polyp of colon)',\n",
       "       'Diagnoses - ICD10 (L409 - L40.9 Psoriasis, unspecified)',\n",
       "       'Diagnoses - ICD10 (M159 - M15.9 Polyarthrosis, unspecified)',\n",
       "       'Diagnoses - ICD10 (M1907 - M19.07 Primary arthrosis of other joints (Ankle and foot))',\n",
       "       'Diagnoses - ICD10 (M2126 - M21.26 Flexion deformity (Lower leg))',\n",
       "       'Diagnoses - ICD10 (M4780 - M47.80 Other spondylosis (Multiple sites in spine))',\n",
       "       'Diagnoses - ICD10 (M4802 - M48.02 Spinal stenosis (Cervical region))',\n",
       "       'Diagnoses - ICD10 (M545 - M54.5 Low back pain)',\n",
       "       'Diagnoses - ICD10 (M7965 - M79.65 Pain in limb (Pelvic region and thigh))',\n",
       "       'Diagnoses - ICD10 (N200 - N20.0 Calculus of kidney)',\n",
       "       'Diagnoses - ICD10 (N760 - N76.0 Acute vaginitis)',\n",
       "       'Diagnoses - ICD10 (N764 - N76.4 Abscess of vulva)',\n",
       "       'Diagnoses - ICD10 (O709 - O70.9 Perineal laceration during delivery, unspecified)',\n",
       "       'Diagnoses - ICD10 (R11 - R11 Nausea and vomiting)',\n",
       "       'Diagnoses - ICD10 (R521 - R52.1 Chronic intractable pain)',\n",
       "       'Diagnoses - ICD10 (R53 - R53 Malaise and fatigue)',\n",
       "       'Diagnoses - ICD10 (S001 - S00.1 Contusion of eyelid and periocular area)',\n",
       "       'Diagnoses - ICD10 (S643 - S64.3 Injury of digital nerve of thumb)',\n",
       "       'Diagnoses - ICD10 (S8260 - S82.60 Fracture of lateral malleolus (closed))',\n",
       "       'Diagnoses - ICD10 (U838 - U83.8 Resistance to other single specified antibiotic)',\n",
       "       'Diagnoses - ICD10 (V184 - V18.4 Driver injured in traffic accident)',\n",
       "       'Diagnoses - ICD10 (W259 - W25.9 Unspecified place)',\n",
       "       'Diagnoses - ICD10 (X509 - X50.9 Unspecified place)',\n",
       "       'Diagnoses - ICD10 (Z867 - Z86.7 Personal history of diseases of the circulatory system)',\n",
       "       'Operative procedures - OPCS4 (A842 - A84.2 Electromyography)',\n",
       "       'Operative procedures - OPCS4 (A843 - A84.3 Nerve conduction studies)',\n",
       "       'Operative procedures - OPCS4 (B295 - B29.5 Revision of reconstruction of breast)',\n",
       "       'Operative procedures - OPCS4 (F093 - F09.3 Surgical removal of wisdom tooth NEC)',\n",
       "       'Operative procedures - OPCS4 (F161 - F16.1 Drainage of abscess of alveolus of tooth)',\n",
       "       'Operative procedures - OPCS4 (L722 - L72.2 Monitoring of arterial pressure)',\n",
       "       'Operative procedures - OPCS4 (L943 - L94.3 Percutaneous transluminal insertion of subcutaneous port)',\n",
       "       'Operative procedures - OPCS4 (P291 - P29.1 Freeing of adhesions of vagina)',\n",
       "       'Operative procedures - OPCS4 (Q013 - Q01.3 Excision of lesion of cervix uteri)',\n",
       "       'Operative procedures - OPCS4 (Q353 - Q35.3 Endoscopic bilateral ringing of fallopian tubes)',\n",
       "       'Operative procedures - OPCS4 (Q558 - Q55.8 Other specified other examination of female genital tract)',\n",
       "       'Operative procedures - OPCS4 (S473 - S47.3 Incision of lesion of skin of head or neck)',\n",
       "       'Operative procedures - OPCS4 (T313 - T31.3 Excision of lesion of anterior abdominal wall NEC)',\n",
       "       'Operative procedures - OPCS4 (U051 - U05.1 Computed tomography of head)',\n",
       "       'Operative procedures - OPCS4 (U211 - U21.1 Magnetic resonance imaging NEC)',\n",
       "       'Operative procedures - OPCS4 (V256 - V25.6 Primary lateral foraminotomy of lumbar spine)',\n",
       "       'Operative procedures - OPCS4 (W843 - W84.3 Endoscopic division of synovial plica)'],\n",
       "      dtype='<U156')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npzfile['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.54908761e-01,  6.09266683e-03,  9.66582546e-01, ...,\n",
       "         8.34674183e-01,  1.76414362e-01,  6.92589060e-01],\n",
       "       [-7.06110535e-01,  9.68633004e-01,  1.06990120e+00, ...,\n",
       "        -3.05937050e-01, -2.46170675e-02, -1.31356283e+00],\n",
       "       [-6.12134001e-01,             nan,  1.30053321e+00, ...,\n",
       "         4.13251721e-02,  1.70997085e-02, -1.23939860e+00],\n",
       "       ...,\n",
       "       [ 2.14533575e-02,  1.22199895e-02,  1.21987648e-02, ...,\n",
       "        -4.75416062e-03,  7.02836494e-03,  5.30153084e-03],\n",
       "       [ 2.21096759e-04, -1.40524247e-02,  6.54376287e-04, ...,\n",
       "         3.05060612e-03, -1.68734389e-03,  5.82131542e-03],\n",
       "       [ 2.26042829e-05, -9.89870768e-03, -7.14665146e-03, ...,\n",
       "        -1.25975021e-02,  8.96067960e-06, -5.09378034e-03]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npzfile['arr_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Lifestyle', 'Lifestyle', 'Lifestyle', 'Lifestyle', 'Lifestyle',\n",
       "       'Lifestyle', 'Lifestyle', 'Physical Activity', 'Lifestyle',\n",
       "       'Lifestyle', 'Diet', 'Diet', 'Diet', 'Diet', 'Diet', 'Diet',\n",
       "       'Diet', 'Diet', 'Diet', 'Diet', 'Diet', 'Diet', 'Diet', 'Diet',\n",
       "       'Diet', 'Diet', 'Diet', 'Diet', 'Diet', 'Diet', 'Diet', 'Alcohol',\n",
       "       'Alcohol', 'Alcohol', 'Alcohol', 'Alcohol', 'Alcohol', 'Alcohol',\n",
       "       'Alcohol', 'Alcohol', 'Tobacco', 'Tobacco', 'Tobacco', 'Tobacco',\n",
       "       'Physical Measurements', 'Physical Measurements',\n",
       "       'Physical Measurements', 'Physical Measurements',\n",
       "       'Physical Measurements', 'Physical Measurements',\n",
       "       'Physical Measurements', 'Physical Measurements',\n",
       "       'Physical Measurements', 'Physical Measurements',\n",
       "       'Physical Measurements', 'Physical Measurements',\n",
       "       'Physical Measurements', 'Physical Measurements',\n",
       "       'Physical Measurements', 'Physical Measurements',\n",
       "       'Physical Measurements', 'Physical Measurements',\n",
       "       'Physical Measurements', 'Physical Measurements',\n",
       "       'Physical Measurements', 'Physical Measurements',\n",
       "       'Physical Measurements', 'Physical Measurements',\n",
       "       'Physical Measurements', 'Physical Measurements',\n",
       "       'Physical Measurements', 'Physical Measurements',\n",
       "       'Physical Measurements', 'Physical Measurements',\n",
       "       'Physical Measurements', 'Physical Measurements',\n",
       "       'Physical Measurements', 'Physical Measurements',\n",
       "       'Physical Measurements', 'Physical Measurements',\n",
       "       'Physical Measurements', 'Physical Measurements',\n",
       "       'Physical Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Skeletal Measurements', 'Skeletal Measurements',\n",
       "       'Cardiac & Circulartory Measurements',\n",
       "       'Cardiac & Circulartory Measurements',\n",
       "       'Cardiac & Circulartory Measurements',\n",
       "       'Cardiac & Circulartory Measurements',\n",
       "       'Cardiac & Circulartory Measurements',\n",
       "       'Cardiac & Circulartory Measurements',\n",
       "       'Cardiac & Circulartory Measurements',\n",
       "       'Cardiac & Circulartory Measurements',\n",
       "       'Cardiac & Circulartory Measurements', 'Hearing Test',\n",
       "       'Hearing Test', 'Hearing Test', 'Hearing Test', 'Hearing Test',\n",
       "       'Hearing Test', 'Hearing Test', 'Eye Test', 'Eye Test',\n",
       "       'Physical Test', 'Blood Assays', 'Blood Assays', 'Cognitive Tests',\n",
       "       'Cognitive Tests', 'Cognitive Tests', 'Cognitive Tests',\n",
       "       'Cognitive Tests', 'Cognitive Tests', 'Cognitive Tests',\n",
       "       'Cognitive Tests', 'Cognitive Tests', 'Cognitive Tests',\n",
       "       'Cognitive Tests', 'Cognitive Tests', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History',\n",
       "       'Medical History', 'Medical History', 'Medical History'],\n",
       "      dtype='<U35')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npzfile['arr_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  160,   182,   184,   186,   188,   418,   430,   704,   754,\n",
       "         805,  1204,  1209,  1454,  1517,  1552,  1656,  1657,  1659,\n",
       "        1817,  1866,  1942,  2024,  2027,  2059,  2075,  2225,  2301,\n",
       "        2394,  2421,  2613,  2729,  2778,  2780,  2796,  2798,  2812,\n",
       "        2844,  2865,  2870,  2873,  2922,  3019,  3021,  3036,  3048,\n",
       "        3050,  3052,  3060,  3152,  3164,  3166,  3167,  3183,  3185,\n",
       "        3187,  3189,  3191,  3218,  3220,  3222,  3224,  3230,  3231,\n",
       "        3233,  3235,  3237,  3243,  3245,  3248,  3250,  3252,  3254,\n",
       "        3259,  3261,  3264,  3270,  3272,  3274,  3278,  3281,  3285,\n",
       "        3291,  3295,  3305,  3314,  3316,  3318,  3320,  3322,  3324,\n",
       "        3330,  3331,  3332,  3334,  3336,  3338,  3340,  3347,  3354,\n",
       "        3375,  3377,  3379,  3380,  3382,  3384,  3386,  3388,  3390,\n",
       "        3392,  3396,  3398,  3400,  3401,  3402,  3404,  3406,  3408,\n",
       "        3410,  3412,  3414,  3416,  3418,  3420,  3422,  3424,  3426,\n",
       "        3428,  3430,  3434,  3436,  3440,  3442,  3444,  3446,  3448,\n",
       "        3456,  3460,  3462,  3464,  3468,  3504,  3505,  3508,  3512,\n",
       "        3513,  3514,  3515,  3521,  4229,  4328,  4385,  4533,  4583,\n",
       "        4618,  4830,  4964,  5139,  5432,  5582,  6113,  6116,  6340,\n",
       "        6696,  6936,  6943,  7064,  7133,  7153,  7156,  7171,  7173,\n",
       "        7216,  7257,  7558,  7566,  7616,  7618,  7689,  7802,  7899,\n",
       "        7903,  7925,  8046,  8050,  8058,  8106,  8137,  8141,  8155,\n",
       "        8252,  8284,  8411,  8433,  8455,  8516,  8563,  8566,  8599,\n",
       "        8607,  8616,  8634,  8637,  8641,  8717,  8724,  8760,  8781,\n",
       "        8923,  9021,  9036,  9146,  9232,  9252,  9329,  9451,  9590,\n",
       "        9717,  9798,  9818,  9868,  9959, 10047, 10185, 10221, 10255,\n",
       "       10368, 10417, 10611, 10737, 10843, 10900, 10926, 10990, 11021,\n",
       "       11051, 11063, 11066, 11159, 11163, 11392, 11442, 11467, 11489,\n",
       "       11512, 11544, 11548, 11653, 11673, 11724, 11732, 11751, 11850,\n",
       "       11880, 11918, 11977, 11982, 11987, 12008, 12055, 12056, 12081,\n",
       "       12083, 12414, 12473, 12476, 12612, 12674, 12737, 12772, 12806,\n",
       "       12860, 12861, 12939, 12961, 13255, 13331, 13347, 13413, 13519,\n",
       "       13586, 13588, 13622, 13691, 13719, 13783, 13927, 13951, 13952,\n",
       "       14000, 14138, 14199, 14251, 14285, 14303, 14311, 14331, 14352,\n",
       "       14549, 14611, 14629, 14678, 14679, 14763, 14804, 14830, 14894,\n",
       "       14951, 14961, 14980, 15060, 15073, 15096, 15158, 15200, 15262,\n",
       "       15264, 15361, 15415, 15481, 15484, 15531, 15609, 15635, 15707,\n",
       "       15714, 15772, 15792, 15970, 16109, 16110, 16124, 16333, 16342,\n",
       "       16514, 16539, 16653, 16656, 16704, 16720, 16795, 16845, 16923,\n",
       "       16949, 16968, 17096])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npzfile['arr_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_df, bonferroni_threshold, false_discovery_rate = correlations_and_plots(\n",
    "#                                     age_delta_decon = age_delta_decon, deconf_subset = vars_i_deconf_subset, \n",
    "#                                     names_subset = varsHeader_subset, idxs = varsIDX_subset,\n",
    "#                                     categories_subset = vars_categories_subset,\n",
    "#                                     title = modality, corr_flag='vars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ethnic Background', 'Ethnic Background', 'Ethnic Background', ...,\n",
       "       'Mental Health', 'Mental Health', 'Mental Health'], dtype='<U35')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_categories_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_to_be_ignored = [21269692]\n",
    "subject_sex = 'female'\n",
    "prototype_flag = True\n",
    "permutation_n_resamples = 276200 # otherwise 5000\n",
    "load_top_flag = True\n",
    "\n",
    "deconfound_flag = True\n",
    "vars_cutoff_nan = 0.1\n",
    "\n",
    "# Identify Correct File to Load\n",
    "\n",
    "IDP_file = '../Analsysis Female New/female_test_IDPs.h5'\n",
    "confounds_file = '../Analsysis Female New/female_test_conf12.h5'\n",
    "data_file = 'female_test.pkl'\n",
    "\n",
    "confounds = h5py.File(confounds_file, 'r')\n",
    "confounds = confounds['conf12'][()]\n",
    "\n",
    "IDP_h5 = h5py.File(IDP_file, 'r')\n",
    "subjects_h5 = IDP_h5['subjects'][()]\n",
    "\n",
    "# Load the relevant dataframe based on the required modality\n",
    "\n",
    "df = pd.read_pickle(data_file)\n",
    "\n",
    "IDP_h5 = h5py.File(IDP_file, 'r')\n",
    "vars_i_deconf = IDP_h5['vars_i_deconf'][()]\n",
    "subjects_h5 = IDP_h5['subjects'][()]\n",
    "\n",
    "with open('../Analsysis Female New/varsHeader.txt') as f:\n",
    "    varsHeader = f.readlines()\n",
    "    varsHeader = [l.strip('\\n\\r') for l in varsHeader]\n",
    "    varsHeader = np.array(varsHeader)\n",
    "with open('../Analsysis Female New/vars_categories.txt') as f:\n",
    "    vars_categories = f.readlines()\n",
    "    vars_categories = [l.strip('\\n\\r') for l in vars_categories]\n",
    "    vars_categories = np.array(vars_categories)\n",
    "\n",
    "varsIDX = np.arange(0, len(varsHeader), 1).astype(int)\n",
    "\n",
    "vars_perc_not_nan = np.sum(np.isnan(vars_i_deconf)==False,axis=0) / vars_i_deconf.shape[0]\n",
    "vars_idx_nan_cutoff = np.where(vars_perc_not_nan >= vars_cutoff_nan)[0]\n",
    "\n",
    "varsHeader_subset = varsHeader[vars_idx_nan_cutoff]\n",
    "vars_i_deconf_subset = vars_i_deconf[:, vars_idx_nan_cutoff]\n",
    "vars_categories_subset = vars_categories[vars_idx_nan_cutoff]\n",
    "varsIDX_subset = varsIDX[vars_idx_nan_cutoff]\n",
    "\n",
    "del IDP_h5\n",
    "\n",
    "vars_corrs = []\n",
    "vars_mods = []\n",
    "vars_bnf_thrs = []\n",
    "vars_fdr_thrs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconfound_inputs(y):\n",
    "    \n",
    "    y = y - y.mean(axis=0)\n",
    "    if np.sum(np.isnan(y)) == 0:\n",
    "        beta = np.linalg.pinv(confounds).dot(y)\n",
    "        beta[np.abs(beta) < 1e-10] = 0\n",
    "        yd = y - confounds.dot(beta)\n",
    "        yd = yd - yd.mean()\n",
    "    else:\n",
    "        print('ERROR! Encoundered a NaN! Function Needs Updating!')\n",
    "    \n",
    "    return yd\n",
    "\n",
    "def apply_FDR_correction(p_values):\n",
    "    '''\n",
    "    Code addapted from Emma Bluemke & Nicola Dinsdale\n",
    "    Wrapper for Benjamini/Hochberg (non-negative) p-value correction for multiple tests.\n",
    "    '''\n",
    "    p_values_corrected = mt.multipletests(p_values, alpha=0.05, method='fdr_bh')[1] \n",
    "    \n",
    "    return p_values_corrected\n",
    "\n",
    "\n",
    "def standardize_data(variables):\n",
    "    '''\n",
    "    Code addapted from Emma Bluemke & Nicola Dinsdale\n",
    "    '''\n",
    "\n",
    "    number_of_subjects=variables.shape[0]\n",
    "\n",
    "    # Compute the arithmetic mean & std along the specified axis, ignoring NaNs.\n",
    "    variables_mean_ignore_NaNs = np.nanmean(variables,axis=0)\n",
    "    variables_std_ignore_NaNs = np.nanstd(variables,axis=0)\n",
    "\n",
    "    # We standardize the data\n",
    "    variables_scaled = variables - np.tile(variables_mean_ignore_NaNs,(number_of_subjects,1))\n",
    "    variables_scaled = variables_scaled / np.tile(variables_std_ignore_NaNs,(number_of_subjects,1))\n",
    "\n",
    "    # Calculate how many variables are non NaN\n",
    "    number_of_non_NaN =np.sum(np.isnan(variables)==False,axis=0) #np.nanstd has N**0.5 in divisor\n",
    "\n",
    "    return variables_scaled, number_of_non_NaN\n",
    "\n",
    "\n",
    "def align_subjects(subjects_df, subjects_h5, age_delta_decon, subjects_to_be_ignored):\n",
    "    '''\n",
    "    Here we make sure that the subjects match between the results and the nIDP/IDP dataframes\n",
    "    The subjects_df uses slightly older data, and subjects might have left the study since it's generation\n",
    "    If need be, this will be corrected at a later stage!\n",
    "    '''\n",
    "    \n",
    "    if len(subjects_df) == len(subjects_h5):\n",
    "        assert (subjects_df == subjects_h5).all()\n",
    "    else:\n",
    "        idx_elim = np.where(subjects_df == subjects_to_be_ignored)[0][0]\n",
    "        subjects_df = np.delete(subjects_df, idx_elim)\n",
    "        assert (subjects_df == subjects_h5).all()\n",
    "        age_delta_decon = np.delete(age_delta_decon, idx_elim)\n",
    "    return subjects_df, age_delta_decon\n",
    "\n",
    "\n",
    "def statistic(x, y):\n",
    "    return pearsonr(x,y)[0]\n",
    "    \n",
    "\n",
    "def correlate_with_fdr_correction(deltas, ukb_variables, permutation_n_resamples=5000):\n",
    "    \"\"\"\n",
    "    Code addapted from Emma Bluemke & Nicola Dinsdale\n",
    "\n",
    "    correlate age deltas with rows in ukb_variables\n",
    "    returns pearson_r, t_test_statistic, p_values_corrected, p_values of length number_of_variables\n",
    "\n",
    "    pearson_r = raw Pearson correlation value (between -1 and 1)\n",
    "    t_test_statistic t test statistic for each variable ()\n",
    "    p_values_corrected is corrected p-values values (fdr corrected)\n",
    "    p_values is non corrected p-values\n",
    "    \"\"\"\n",
    "\n",
    "    ukb_variables_scaled , ukb_variales_number_of_non_NaN = standardize_data(ukb_variables)\n",
    "    ukb_variables_NaN_matrix = np.isnan(ukb_variables_scaled)\n",
    "    ukb_variables_scaled[ukb_variables_NaN_matrix] = 0\n",
    "\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    number_of_variables = ukb_variables_scaled.shape[1]\n",
    "\n",
    "    deltas_array = np.tile(deltas,(number_of_variables,1)).T\n",
    "    deltas_array[ukb_variables_NaN_matrix] = np.nan\n",
    "    deltas_array = standardize_data(deltas_array)[0]\n",
    "    deltas_array[ukb_variables_NaN_matrix] = 0\n",
    "\n",
    "#     pearson_r = np.sum(deltas_array * ukb_variables_scaled, axis=0) / ukb_variales_number_of_non_NaN\n",
    "    pearson_r = np.zeros(deltas_array.shape[1])\n",
    "    p_values = np.zeros(deltas_array.shape[1])\n",
    "    \n",
    "    for idx in range(pearson_r.shape[0]):\n",
    "        # CHANGE HERE THAT the zeros at nan-matrix locations are discarded, so we have only valid values for permutation testing\n",
    "        deltas_array_permute = np.delete(deltas_array[:,idx], ukb_variables_NaN_matrix[:,idx])\n",
    "        ukb_variables_scaled_permute = np.delete(ukb_variables_scaled[:,idx], ukb_variables_NaN_matrix[:,idx])\n",
    "        \n",
    "        res = permutation_test(\n",
    "            (deltas_array_permute, ukb_variables_scaled_permute), \n",
    "            statistic, \n",
    "            permutation_type='pairings', \n",
    "            n_resamples=permutation_n_resamples, \n",
    "            random_state=1\n",
    "        )\n",
    "        \n",
    "        pearson_r[idx] = res.statistic\n",
    "        p_values[idx] = res.pvalue\n",
    "        \n",
    "        print(\"\\r Processed {:.3f}%: {}/{} permutations\".format(idx/len(pearson_r) * 100.0, idx+1, len(pearson_r)), end='')\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    t_test_statistic = pearson_r * ((ukb_variales_number_of_non_NaN-2)/(1-pearson_r**2))**0.5\n",
    "    t_test_statistic = np.abs(t_test_statistic)\n",
    "    t_test_statistic[ukb_variales_number_of_non_NaN <= 2] = np.nan #set those that had d.o.f 0 to nan\n",
    "\n",
    "#     p_values=np.zeros(len(t_test_statistic))\n",
    "    for j in range(len(t_test_statistic)):\n",
    "        if t_test_statistic[j] is not np.nan:\n",
    "#             p_values[j] = student_t.sf(t_test_statistic[j], ukb_variales_number_of_non_NaN[j] - 2) * 2\n",
    "            pass\n",
    "        else:\n",
    "            p_values[j]=np.nan\n",
    "\n",
    "    p_values_NaN_matrix = np.isnan(p_values)\n",
    "    p_values_no_NaN = p_values[p_values_NaN_matrix==False]\n",
    "    p_values_corrected_raw = apply_FDR_correction(p_values_no_NaN)\n",
    "\n",
    "    p_values_corrected=np.zeros(len(p_values))\n",
    "    p_values_corrected[p_values_NaN_matrix==False] = p_values_corrected_raw\n",
    "    p_values_corrected[p_values_NaN_matrix==True] = np.nan\n",
    "\n",
    "    return pearson_r, t_test_statistic, p_values_corrected, p_values\n",
    "\n",
    "\n",
    "def correlations_and_plots(age_delta_decon, deconf_subset, names_subset, idxs, categories_subset, title, \n",
    "                           corr_flag='IDP', permutation_n_resamples=5000):\n",
    "    \n",
    "    corr_results = correlate_with_fdr_correction(age_delta_decon, deconf_subset, \n",
    "                                                 permutation_n_resamples=permutation_n_resamples)\n",
    "    \n",
    "    corr_df = pd.DataFrame.from_dict({\n",
    "        'idx': idxs,\n",
    "        \"names\": names_subset,\n",
    "        'Categories': categories_subset,\n",
    "        \"pearson_r\": corr_results[0],\n",
    "        \"t_test_statistic\": corr_results[1],\n",
    "        \"p_values_corrected\": corr_results[2],\n",
    "        \"p_values\": corr_results[3],\n",
    "        \"abs_pearson_r\": np.abs(corr_results[0]),\n",
    "        \"log_p_values\": -np.log10(corr_results[3]),\n",
    "        \"log_p_values_corrected\": -np.log10(corr_results[2]),\n",
    "    })\n",
    "    \n",
    "    if corr_flag == 'IDP':\n",
    "        short_p_values = np.extract(corr_df.p_values !=0, corr_df.p_values)\n",
    "        bonferroni_threshold = 0.05/len(short_p_values) #... Bonferroni\n",
    "    else:\n",
    "        bonferroni_threshold = 0.05/len(corr_df.p_values) #... Bonferroni\n",
    "    bonferroni_threshold = -np.log10(bonferroni_threshold)\n",
    "\n",
    "    arguments = np.argsort(corr_df.p_values_corrected)\n",
    "    sorted_p_values_corrected = corr_df.p_values_corrected[arguments]\n",
    "    sorted_p_values = corr_df.p_values[arguments]\n",
    "    if len(sorted_p_values_corrected[sorted_p_values_corrected<=0.05]):\n",
    "        false_discovery_rate = np.nanmax(sorted_p_values[sorted_p_values_corrected<=0.05])\n",
    "        false_discovery_rate = -np.log10(false_discovery_rate)\n",
    "    else:\n",
    "\n",
    "        false_discovery_rate = None\n",
    "    \n",
    "    return corr_df, bonferroni_threshold, false_discovery_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logpOver2_0.npz\n"
     ]
    }
   ],
   "source": [
    "if load_top_flag == True:\n",
    "\n",
    "    filename = 'logpOver2_' + str(idx) + '.npz'\n",
    "    print(filename)\n",
    "\n",
    "    npzfile = np.load(filename)\n",
    "    varsHeader_subset = np.copy(npzfile['arr_0'])\n",
    "    vars_i_deconf_subset = np.copy(npzfile['arr_1']).T\n",
    "    vars_categories_subset = np.copy(npzfile['arr_2'])\n",
    "    varsIDX_subset = np.copy(npzfile['arr_3'])\n",
    "    del npzfile\n",
    "\n",
    "df_mod = df.iloc[idx].dataframe\n",
    "modality = df.iloc[idx].modality\n",
    "age_delta_decon = df_mod.age_delta_decon.to_numpy()\n",
    "subjects = df_mod['Unnamed: 0'].to_numpy()\n",
    "subjects, age_delta_decon = align_subjects(subjects, subjects_h5, \n",
    "                                              age_delta_decon, subjects_to_be_ignored)\n",
    "\n",
    "if deconfound_flag == True:\n",
    "    age_delta_decon = deconfound_inputs(age_delta_decon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_delta_decon = age_delta_decon\n",
    "deconf_subset = vars_i_deconf_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas =  age_delta_decon\n",
    "ukb_variables = deconf_subset\n",
    "permutation_n_resamples=permutation_n_resamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukb_variables_scaled , ukb_variales_number_of_non_NaN = standardize_data(ukb_variables)\n",
    "ukb_variables_NaN_matrix = np.isnan(ukb_variables_scaled)\n",
    "ukb_variables_scaled[ukb_variables_NaN_matrix] = 0\n",
    "\n",
    "sys.stdout.flush()\n",
    "\n",
    "number_of_variables = ukb_variables_scaled.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas_array = np.tile(deltas,(number_of_variables,1)).T\n",
    "deltas_array[ukb_variables_NaN_matrix] = np.nan\n",
    "deltas_array = standardize_data(deltas_array)[0]\n",
    "deltas_array[ukb_variables_NaN_matrix] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345, 5021)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ukb_variables_NaN_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345, 5021)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ukb_variables_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5021,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ukb_variales_number_of_non_NaN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345, 5021)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ukb_variables.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5021, 345)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_i_deconf_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
